{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d149817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Neural Network Architectures for DDQN Trading System\n",
    "Combines LSTM for feature extraction with DDQN for trading decisions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff23e74",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd3250d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class LSTMFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM for extracting features from time series data\n",
    "    Processes (batch_size, sequence_length, n_features) sequences\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features: int, sequence_length: int):\n",
    "        super(LSTMFeatureExtractor, self).__init__()\n",
    "        \n",
    "        self.n_features = n_features\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # LSTM parameters\n",
    "        self.hidden_size = config.LSTM_HIDDEN_SIZE\n",
    "        self.num_layers = config.LSTM_NUM_LAYERS\n",
    "        self.dropout = config.LSTM_DROPOUT\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=self.dropout if self.num_layers > 1 else 0,\n",
    "            batch_first=True,\n",
    "            bidirectional=config.LSTM_BIDIRECTIONAL\n",
    "        )\n",
    "        \n",
    "        # Calculate LSTM output size\n",
    "        self.lstm_output_size = self.hidden_size * (2 if config.LSTM_BIDIRECTIONAL else 1)\n",
    "        \n",
    "        # Additional processing layers\n",
    "        self.feature_processor = nn.Sequential(\n",
    "            nn.Linear(self.lstm_output_size, config.LSTM_PROCESSING_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.LSTM_DROPOUT),\n",
    "            nn.Linear(config.LSTM_PROCESSING_DIM, config.LSTM_PROCESSING_DIM // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.LSTM_DROPOUT)\n",
    "        )\n",
    "        \n",
    "        # Output dimension\n",
    "        self.output_dim = config.LSTM_PROCESSING_DIM // 2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through LSTM\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, sequence_length, n_features)\n",
    "        \n",
    "        Returns:\n",
    "            Extracted features of shape (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        # Initialize hidden state\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(\n",
    "            self.num_layers * (2 if config.LSTM_BIDIRECTIONAL else 1),\n",
    "            batch_size,\n",
    "            self.hidden_size,\n",
    "            device=x.device\n",
    "        )\n",
    "        c0 = torch.zeros(\n",
    "            self.num_layers * (2 if config.LSTM_BIDIRECTIONAL else 1),\n",
    "            batch_size,\n",
    "            self.hidden_size,\n",
    "            device=x.device\n",
    "        )\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        lstm_out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Use the last output from the sequence\n",
    "        # If bidirectional, lstm_out[:, -1, :] contains both forward and backward final states\n",
    "        final_output = lstm_out[:, -1, :]  # (batch_size, lstm_output_size)\n",
    "        \n",
    "        # Process through additional layers\n",
    "        features = self.feature_processor(final_output)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec436b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DQNNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Q-Network that combines LSTM features with trading state features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, market_feature_dim: int, trading_state_dim: int, \n",
    "                 action_space_size: int, sequence_length: int):\n",
    "        super(DQNNetwork, self).__init__()\n",
    "        \n",
    "        self.market_feature_dim = market_feature_dim\n",
    "        self.trading_state_dim = trading_state_dim\n",
    "        self.action_space_size = action_space_size\n",
    "        \n",
    "        # LSTM for processing market features\n",
    "        self.lstm = LSTMFeatureExtractor(market_feature_dim, sequence_length)\n",
    "        \n",
    "        # Calculate total input dimension for fully connected layers\n",
    "        total_input_dim = self.lstm.output_dim + trading_state_dim\n",
    "        \n",
    "        # Fully connected layers for Q-value estimation\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        \n",
    "        # First hidden layer\n",
    "        self.fc_layers.append(nn.Linear(total_input_dim, config.HIDDEN_DIMS[0]))\n",
    "        \n",
    "        # Additional hidden layers\n",
    "        for i in range(1, len(config.HIDDEN_DIMS)):\n",
    "            self.fc_layers.append(\n",
    "                nn.Linear(config.HIDDEN_DIMS[i-1], config.HIDDEN_DIMS[i])\n",
    "            )\n",
    "        \n",
    "        # Output layer for Q-values\n",
    "        self.q_values = nn.Linear(config.HIDDEN_DIMS[-1], action_space_size)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(config.LSTM_DROPOUT)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights using Xavier initialization\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.LSTM):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    elif 'bias' in name:\n",
    "                        param.data.fill_(0)\n",
    "    \n",
    "    def forward(self, market_features, trading_state):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \n",
    "        Args:\n",
    "            market_features: Market data tensor (batch_size, sequence_length, n_features)\n",
    "            trading_state: Trading state tensor (batch_size, trading_state_dim)\n",
    "        \n",
    "        Returns:\n",
    "            Q-values for each action (batch_size, action_space_size)\n",
    "        \"\"\"\n",
    "        # Extract features from market data using LSTM\n",
    "        lstm_features = self.lstm(market_features)\n",
    "        \n",
    "        # Combine LSTM features with trading state\n",
    "        combined_features = torch.cat([lstm_features, trading_state], dim=1)\n",
    "        \n",
    "        # Pass through fully connected layers\n",
    "        x = combined_features\n",
    "        for fc_layer in self.fc_layers:\n",
    "            x = fc_layer(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Output Q-values\n",
    "        q_values = self.q_values(x)\n",
    "        \n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d2bb4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DoubleDQN(nn.Module):\n",
    "    \"\"\"\n",
    "    Double Deep Q-Network implementation with LSTM\n",
    "    Uses two networks: online and target\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, market_feature_dim: int, trading_state_dim: int,\n",
    "                 action_space_size: int, sequence_length: int):\n",
    "        super(DoubleDQN, self).__init__()\n",
    "        \n",
    "        # Online network (updated frequently)\n",
    "        self.online_net = DQNNetwork(\n",
    "            market_feature_dim, trading_state_dim, action_space_size, sequence_length\n",
    "        )\n",
    "        \n",
    "        # Target network (updated less frequently)\n",
    "        self.target_net = DQNNetwork(\n",
    "            market_feature_dim, trading_state_dim, action_space_size, sequence_length\n",
    "        )\n",
    "        \n",
    "        # Initialize target network with same weights as online network\n",
    "        self.update_target_network()\n",
    "        \n",
    "        # Freeze target network parameters (will be updated via soft updates)\n",
    "        for param in self.target_net.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, market_features, trading_state, use_target=False):\n",
    "        \"\"\"\n",
    "        Forward pass through either online or target network\n",
    "        \n",
    "        Args:\n",
    "            market_features: Market data tensor (batch_size, sequence_length, n_features)\n",
    "            trading_state: Trading state tensor (batch_size, trading_state_dim)\n",
    "            use_target: Whether to use target network\n",
    "        \n",
    "        Returns:\n",
    "            Q-values\n",
    "        \"\"\"\n",
    "        if use_target:\n",
    "            return self.target_net(market_features, trading_state)\n",
    "        else:\n",
    "            return self.online_net(market_features, trading_state)\n",
    "    \n",
    "    def update_target_network(self, tau: float = None):\n",
    "        \"\"\"\n",
    "        Update target network parameters\n",
    "        \n",
    "        Args:\n",
    "            tau: Soft update parameter (None for hard update)\n",
    "        \"\"\"\n",
    "        if tau is None:\n",
    "            # Hard update: copy weights completely\n",
    "            self.target_net.load_state_dict(self.online_net.state_dict())\n",
    "        else:\n",
    "            # Soft update: θ_target = τ*θ_online + (1-τ)*θ_target\n",
    "            for target_param, online_param in zip(\n",
    "                self.target_net.parameters(), self.online_net.parameters()\n",
    "            ):\n",
    "                target_param.data.copy_(\n",
    "                    tau * online_param.data + (1.0 - tau) * target_param.data\n",
    "                )\n",
    "    \n",
    "    def get_action(self, market_features, trading_state, epsilon=0.0):\n",
    "        \"\"\"\n",
    "        Get action using epsilon-greedy policy\n",
    "        \n",
    "        Args:\n",
    "            market_features: Market data tensor (batch_size, sequence_length, n_features)\n",
    "            trading_state: Trading state tensor (batch_size, trading_state_dim)\n",
    "            epsilon: Exploration probability\n",
    "        \n",
    "        Returns:\n",
    "            Selected action\n",
    "        \"\"\"\n",
    "        if np.random.random() < epsilon:\n",
    "            # Random action (exploration)\n",
    "            return np.random.randint(0, self.online_net.action_space_size)\n",
    "        else:\n",
    "            # Greedy action (exploitation)\n",
    "            with torch.no_grad():\n",
    "                q_values = self.online_net(market_features, trading_state)\n",
    "                return q_values.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b205ef",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    Experience replay buffer for storing and sampling transitions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, market_features, trading_state, action, reward, \n",
    "             next_market_features, next_trading_state, done):\n",
    "        \"\"\"Store a transition in the buffer\"\"\"\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        \n",
    "        self.buffer[self.position] = (\n",
    "            market_features, trading_state, action, reward,\n",
    "            next_market_features, next_trading_state, done\n",
    "        )\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size: int):\n",
    "        \"\"\"Sample a batch of transitions\"\"\"\n",
    "        batch = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        \n",
    "        market_features = []\n",
    "        trading_states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        next_market_features = []\n",
    "        next_trading_states = []\n",
    "        dones = []\n",
    "        \n",
    "        for idx in batch:\n",
    "            mf, ts, a, r, nmf, nts, d = self.buffer[idx]\n",
    "            market_features.append(mf)\n",
    "            trading_states.append(ts)\n",
    "            actions.append(a)\n",
    "            rewards.append(r)\n",
    "            next_market_features.append(nmf)\n",
    "            next_trading_states.append(nts)\n",
    "            dones.append(d)\n",
    "        \n",
    "        return (\n",
    "            torch.FloatTensor(market_features),\n",
    "            torch.FloatTensor(trading_states),\n",
    "            torch.LongTensor(actions),\n",
    "            torch.FloatTensor(rewards),\n",
    "            torch.FloatTensor(next_market_features),\n",
    "            torch.FloatTensor(next_trading_states),\n",
    "            torch.BoolTensor(dones)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba285ee6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Utility functions for network management\n",
    "def save_model(model: DoubleDQN, filepath: str, optimizer_state: dict = None, \n",
    "               metadata: dict = None):\n",
    "    \"\"\"Save model checkpoint\"\"\"\n",
    "    checkpoint = {\n",
    "        'online_net_state_dict': model.online_net.state_dict(),\n",
    "        'target_net_state_dict': model.target_net.state_dict(),\n",
    "    }\n",
    "    \n",
    "    if optimizer_state:\n",
    "        checkpoint['optimizer_state_dict'] = optimizer_state\n",
    "    \n",
    "    if metadata:\n",
    "        checkpoint['metadata'] = metadata\n",
    "    \n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Model saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155a0b2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_model(model: DoubleDQN, filepath: str, load_optimizer: bool = False):\n",
    "    \"\"\"Load model checkpoint\"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location=config.DEVICE)\n",
    "    \n",
    "    model.online_net.load_state_dict(checkpoint['online_net_state_dict'])\n",
    "    model.target_net.load_state_dict(checkpoint['target_net_state_dict'])\n",
    "    \n",
    "    optimizer_state = None\n",
    "    if load_optimizer and 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer_state = checkpoint['optimizer_state_dict']\n",
    "    \n",
    "    metadata = checkpoint.get('metadata', {})\n",
    "    \n",
    "    print(f\"Model loaded from {filepath}\")\n",
    "    return optimizer_state, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e85994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing LSTM neural network architectures...\")\n",
    "    \n",
    "    # Test parameters\n",
    "    batch_size = 32\n",
    "    market_feature_dim = 25\n",
    "    trading_state_dim = 8\n",
    "    action_space_size = 9\n",
    "    sequence_length = 30\n",
    "    \n",
    "    # Create test data - NOTE: Different shape for LSTM\n",
    "    market_features = torch.randn(batch_size, sequence_length, market_feature_dim)\n",
    "    trading_state = torch.randn(batch_size, trading_state_dim)\n",
    "    \n",
    "    # Test LSTM feature extractor\n",
    "    lstm = LSTMFeatureExtractor(market_feature_dim, sequence_length)\n",
    "    lstm_output = lstm(market_features)\n",
    "    print(f\"LSTM output shape: {lstm_output.shape}\")\n",
    "    \n",
    "    # Test DQN network\n",
    "    dqn = DQNNetwork(market_feature_dim, trading_state_dim, action_space_size, sequence_length)\n",
    "    q_values = dqn(market_features, trading_state)\n",
    "    print(f\"DQN Q-values shape: {q_values.shape}\")\n",
    "    \n",
    "    # Test Double DQN\n",
    "    ddqn = DoubleDQN(market_feature_dim, trading_state_dim, action_space_size, sequence_length)\n",
    "    \n",
    "    # Test online network\n",
    "    online_q_values = ddqn(market_features, trading_state, use_target=False)\n",
    "    print(f\"Online network Q-values shape: {online_q_values.shape}\")\n",
    "    \n",
    "    # Test target network\n",
    "    target_q_values = ddqn(market_features, trading_state, use_target=True)\n",
    "    print(f\"Target network Q-values shape: {target_q_values.shape}\")\n",
    "    \n",
    "    # Test action selection\n",
    "    action = ddqn.get_action(market_features[0:1], trading_state[0:1], epsilon=0.1)\n",
    "    print(f\"Selected action: {action}\")\n",
    "    \n",
    "    print(\"LSTM neural network testing complete!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
