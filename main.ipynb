{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main execution script for DDQN Trading System\n",
    "Coordinates data loading, training, and backtesting\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our modules\n",
    "import config\n",
    "from data_handler import TradingDataHandler\n",
    "from environment import TradingEnvironmentWrapper\n",
    "from ddqn_agent import DDQNTradingAgent, create_agent_from_env\n",
    "from networks import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0150de",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75e038",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_directories():\n",
    "    \"\"\"Create necessary directories for saving models and results\"\"\"\n",
    "    directories = [config.MODEL_SAVE_PATH, config.LOG_SAVE_PATH, config.RESULTS_SAVE_PATH]\n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    print(\"Directories created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3978d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data(csv_path: str):\n",
    "    \"\"\"\n",
    "    Load and prepare data for training\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to CSV file\n",
    "        \n",
    "    Returns:\n",
    "        data_splits: Dictionary containing train/val/test splits\n",
    "        data_handler: Data handler instance\n",
    "    \"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    \n",
    "    # Initialize data handler\n",
    "    data_handler = TradingDataHandler(csv_path)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    raw_data = data_handler.load_data()\n",
    "    processed_data = data_handler.preprocess_data()\n",
    "    \n",
    "    # Create sequences for CNN\n",
    "    sequences, targets, dates = data_handler.create_sequences(\n",
    "        processed_data, \n",
    "        lookback=config.LOOKBACK_WINDOW\n",
    "    )\n",
    "    \n",
    "    # Split data\n",
    "    data_splits = data_handler.split_data(\n",
    "        sequences, targets, dates, \n",
    "        quick_test=config.QUICK_TEST_MODE\n",
    "    )\n",
    "    \n",
    "    # Print data information\n",
    "    feature_info = data_handler.get_feature_info()\n",
    "    print(f\"\\nData Information:\")\n",
    "    print(f\"  Features: {feature_info['n_features']}\")\n",
    "    print(f\"  Samples: {feature_info['n_samples']}\")\n",
    "    print(f\"  Date range: {feature_info['date_range'][0]} to {feature_info['date_range'][1]}\")\n",
    "    print(f\"  Lookback window: {config.LOOKBACK_WINDOW} days\")\n",
    "    \n",
    "    return data_splits, data_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1230fe4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_environments(data_splits):\n",
    "    \"\"\"\n",
    "    Create trading environments for train/validation/test\n",
    "    \n",
    "    Args:\n",
    "        data_splits: Data splits dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Environment wrapper and individual environments\n",
    "    \"\"\"\n",
    "    print(\"Creating trading environments...\")\n",
    "    \n",
    "    # Create environment wrapper\n",
    "    env_wrapper = TradingEnvironmentWrapper(data_splits)\n",
    "    \n",
    "    # Create individual environments\n",
    "    train_env = env_wrapper.create_env('train')\n",
    "    val_env = env_wrapper.create_env('val')\n",
    "    test_env = env_wrapper.create_env('test')\n",
    "    \n",
    "    # Print environment information\n",
    "    env_info = env_wrapper.get_env_info()\n",
    "    for split, info in env_info.items():\n",
    "        print(f\"\\n{split.upper()} Environment:\")\n",
    "        print(f\"  Samples: {info['n_samples']}\")\n",
    "        print(f\"  State size: {info['state_size']}\")\n",
    "        print(f\"  Action space: {info['action_space_size']}\")\n",
    "        print(f\"  Date range: {info['date_range'][0]} to {info['date_range'][1]}\")\n",
    "    \n",
    "    return env_wrapper, train_env, val_env, test_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08736c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_agent(train_env, val_env):\n",
    "    \"\"\"\n",
    "    Train the DDQN agent\n",
    "    \n",
    "    Args:\n",
    "        train_env: Training environment\n",
    "        val_env: Validation environment\n",
    "        \n",
    "    Returns:\n",
    "        Trained agent and training history\n",
    "    \"\"\"\n",
    "    print(\"\\nInitializing DDQN agent...\")\n",
    "    \n",
    "    # Create agent\n",
    "    agent = create_agent_from_env(train_env)\n",
    "    \n",
    "    # Determine number of episodes\n",
    "    num_episodes = config.QUICK_TEST_EPISODES if config.QUICK_TEST_MODE else config.EPISODES\n",
    "    \n",
    "    print(f\"Starting training for {num_episodes} episodes...\")\n",
    "    print(f\"Quick test mode: {config.QUICK_TEST_MODE}\")\n",
    "    \n",
    "    # Train agent\n",
    "    training_history = agent.train(train_env, val_env, num_episodes)\n",
    "    \n",
    "    # Plot training curves\n",
    "    if config.PLOT_TRAINING_CURVES:\n",
    "        save_path = f\"{config.RESULTS_SAVE_PATH}training_curves.png\" if config.SAVE_PLOTS else None\n",
    "        agent.plot_training_curves(training_history, save_path)\n",
    "    \n",
    "    # Save final agent\n",
    "    agent.save_agent(\n",
    "        f\"{config.MODEL_SAVE_PATH}final_agent.pth\",\n",
    "        {'training_complete': True, 'timestamp': datetime.now().isoformat()}\n",
    "    )\n",
    "    \n",
    "    return agent, training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8912184",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def backtest_agent(agent, test_env):\n",
    "    \"\"\"\n",
    "    Backtest the trained agent\n",
    "    \n",
    "    Args:\n",
    "        agent: Trained DDQN agent\n",
    "        test_env: Test environment\n",
    "        \n",
    "    Returns:\n",
    "        Backtesting results\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting backtesting...\")\n",
    "    \n",
    "    # Load best model for backtesting\n",
    "    try:\n",
    "        agent.load_agent(f\"{config.MODEL_SAVE_PATH}best_model.pth\")\n",
    "        print(\"Loaded best model for backtesting\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Best model not found, using current model\")\n",
    "    \n",
    "    # Run backtest\n",
    "    backtest_results = agent.backtest(test_env)\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame([backtest_results['performance_metrics']])\n",
    "    results_df.to_csv(f\"{config.RESULTS_SAVE_PATH}backtest_results.csv\", index=False)\n",
    "    \n",
    "    return backtest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b17727",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_backtest_results(test_env, backtest_results):\n",
    "    \"\"\"\n",
    "    Plot comprehensive backtesting results\n",
    "    \n",
    "    Args:\n",
    "        test_env: Test environment used for backtesting\n",
    "        backtest_results: Results from backtesting\n",
    "    \"\"\"\n",
    "    if not config.PLOT_TRADING_RESULTS:\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Equity curve\n",
    "    equity_curve = test_env.equity_curve\n",
    "    dates = test_env.data_dates[:len(equity_curve)]\n",
    "    \n",
    "    axes[0, 0].plot(dates, equity_curve, linewidth=2, alpha=0.8)\n",
    "    axes[0, 0].set_title('Equity Curve', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Date')\n",
    "    axes[0, 0].set_ylabel('Equity ($)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Drawdown\n",
    "    peak = np.maximum.accumulate(equity_curve)\n",
    "    drawdown = (peak - equity_curve) / peak\n",
    "    \n",
    "    axes[0, 1].fill_between(dates, drawdown, 0, alpha=0.7, color='red')\n",
    "    axes[0, 1].set_title('Drawdown', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Date')\n",
    "    axes[0, 1].set_ylabel('Drawdown (%)')\n",
    "    axes[0, 1].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Action distribution\n",
    "    action_dist = backtest_results['action_distribution']\n",
    "    actions = list(action_dist.keys())\n",
    "    counts = list(action_dist.values())\n",
    "    action_labels = [f\"Action {a}\\n({config.POSITION_ACTIONS[a]:+.0%})\" for a in actions]\n",
    "    \n",
    "    axes[1, 0].bar(action_labels, counts, alpha=0.8)\n",
    "    axes[1, 0].set_title('Action Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Action')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Performance metrics\n",
    "    performance = backtest_results['performance_metrics']\n",
    "    metrics_names = ['Total Return', 'Sharpe Ratio', 'Max Drawdown', 'Win Rate', 'Profit Factor']\n",
    "    metrics_values = [\n",
    "        performance.get('total_return', 0),\n",
    "        performance.get('sharpe_ratio', 0),\n",
    "        performance.get('max_drawdown', 0),\n",
    "        performance.get('win_rate', 0),\n",
    "        performance.get('profit_factor', 0)\n",
    "    ]\n",
    "    \n",
    "    # Format values for display\n",
    "    formatted_values = [\n",
    "        f\"{metrics_values[0]:.1%}\",\n",
    "        f\"{metrics_values[1]:.2f}\",\n",
    "        f\"{metrics_values[2]:.1%}\",\n",
    "        f\"{metrics_values[3]:.1%}\",\n",
    "        f\"{metrics_values[4]:.2f}\"\n",
    "    ]\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = axes[1, 1].bar(metrics_names, metrics_values, alpha=0.8)\n",
    "    axes[1, 1].set_title('Performance Metrics', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Value')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, formatted_val in zip(bars, formatted_values):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + max(metrics_values)*0.01,\n",
    "                       formatted_val, ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if config.SAVE_PLOTS:\n",
    "        plt.savefig(f\"{config.RESULTS_SAVE_PATH}backtest_analysis.png\", \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da0018",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_summary_report(training_history, backtest_results, data_handler):\n",
    "    \"\"\"\n",
    "    Save a comprehensive summary report\n",
    "    \n",
    "    Args:\n",
    "        training_history: Training metrics\n",
    "        backtest_results: Backtesting results\n",
    "        data_handler: Data handler with configuration info\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    report = f\"\"\"\n",
    "DDQN TRADING SYSTEM - SUMMARY REPORT\n",
    "Generated: {timestamp}\n",
    "\n",
    "=== CONFIGURATION ===\n",
    "Commodity: {config.TICK_VALUE} per tick\n",
    "Max Contracts: {config.MAX_CONTRACTS}\n",
    "Lookback Window: {config.LOOKBACK_WINDOW} days\n",
    "Initial Capital: ${config.INITIAL_CAPITAL:,.2f}\n",
    "Quick Test Mode: {config.QUICK_TEST_MODE}\n",
    "\n",
    "=== DATA INFORMATION ===\n",
    "Total Samples: {len(data_handler.processed_data)}\n",
    "Features: {len(config.FEATURE_COLUMNS)}\n",
    "Date Range: {data_handler.processed_data['date'].min()} to {data_handler.processed_data['date'].max()}\n",
    "\n",
    "=== TRAINING RESULTS ===\n",
    "Episodes Trained: {len(training_history['train_rewards'])}\n",
    "Final Training Reward: {training_history['train_rewards'][-1]:.4f}\n",
    "Final Validation Reward: {training_history['val_rewards'][-1]:.4f}\n",
    "Best Validation Performance: {max([p.get('total_return', 0) for p in training_history['val_performance']]):.2%}\n",
    "\n",
    "=== BACKTESTING RESULTS ===\n",
    "Total Return: {backtest_results['performance_metrics'].get('total_return', 0):.2%}\n",
    "Sharpe Ratio: {backtest_results['performance_metrics'].get('sharpe_ratio', 0):.2f}\n",
    "Maximum Drawdown: {backtest_results['performance_metrics'].get('max_drawdown', 0):.2%}\n",
    "Win Rate: {backtest_results['performance_metrics'].get('win_rate', 0):.1%}\n",
    "Profit Factor: {backtest_results['performance_metrics'].get('profit_factor', 0):.2f}\n",
    "Total Trades: {backtest_results['performance_metrics'].get('total_trades', 0)}\n",
    "Final Equity: ${backtest_results['performance_metrics'].get('final_equity', 0):,.2f}\n",
    "\n",
    "=== RISK METRICS ===\n",
    "Transaction Costs: ${config.TRANSACTION_COST_PER_CONTRACT} per contract\n",
    "Slippage: {config.BID_ASK_SLIPPAGE} ticks per contract\n",
    "Max Daily Loss Limit: ${config.MAX_DAILY_LOSS:,.2f}\n",
    "Stop Loss: {config.STOP_LOSS_PERCENTAGE:.1%}\n",
    "\n",
    "=== ACTION ANALYSIS ===\n",
    "Most Used Action: {max(backtest_results['action_distribution'], key=backtest_results['action_distribution'].get)}\n",
    "Action Distribution:\n",
    "\"\"\"\n",
    "    \n",
    "    for action, count in backtest_results['action_distribution'].items():\n",
    "        percentage = count / sum(backtest_results['action_distribution'].values()) * 100\n",
    "        action_desc = config.POSITION_ACTIONS[action]\n",
    "        report += f\"  Action {action} ({action_desc:+.0%}): {count} times ({percentage:.1f}%)\\n\"\n",
    "    \n",
    "    # Save report\n",
    "    with open(f\"{config.RESULTS_SAVE_PATH}summary_report.txt\", 'w') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(\"\\nSummary report saved to results/summary_report.txt\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aaa660",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main(csv_path: str = None):\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to CSV data file\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"DDQN TRADING SYSTEM - GOLDMAN ROLL STRATEGY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create directories\n",
    "    create_directories()\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    if csv_path is None:\n",
    "        print(\"Please provide the path to your CSV file\")\n",
    "        csv_path = input(\"Enter CSV file path: \")\n",
    "    \n",
    "    try:\n",
    "        data_splits, data_handler = load_and_prepare_data(csv_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create environments\n",
    "    env_wrapper, train_env, val_env, test_env = create_environments(data_splits)\n",
    "    \n",
    "    # Train agent\n",
    "    try:\n",
    "        agent, training_history = train_agent(train_env, val_env)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Backtest agent\n",
    "    try:\n",
    "        backtest_results = backtest_agent(agent, test_env)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during backtesting: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Plot results\n",
    "    try:\n",
    "        plot_backtest_results(test_env, backtest_results)\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting results: {e}\")\n",
    "    \n",
    "    # Save summary report\n",
    "    try:\n",
    "        save_summary_report(training_history, backtest_results, data_handler)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving report: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXECUTION COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return agent, backtest_results, training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    import sys\n",
    "    \n",
    "    if len(sys.argv) > 1:\n",
    "        csv_file_path = sys.argv[1]\n",
    "        main(csv_file_path)\n",
    "    else:\n",
    "        # For testing - you would replace this with your actual file path\n",
    "        \n",
    "        csv_file_path = \"C:\\\\MSc-DRL-Project\\\\CSVfiles\\\\CL12 - Sheet1.csv\"\n",
    "\n",
    "        print(f\"No CSV file provided. Please run with: python main.py your_data.csv\")\n",
    "        print(f\"Or modify the csv_file_path variable in main() and uncomment the line below.\")\n",
    "        main(csv_file_path)  # Uncomment this line and provide your CSV path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14002b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
